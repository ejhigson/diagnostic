{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Diagnostics Paper Code\n",
    "\n",
    "Code for making the figures and results tables in \"Diagnostic tests for nested sampling calculations\" ([Higson et al., 2018](https://arxiv.org/abs/1804.06406)). See the paper for a detailed explanation information about the plots and tables produced.\n",
    "\n",
    "Requirements:\n",
    "* Nested sampling runs saved in 'chains' - these can be generated with `generate_data.py`;\n",
    "* `nestcheck`;\n",
    "* `getdist` (<https://github.com/cmbant/getdist>).\n",
    "\n",
    "Optional:\n",
    "* `texunc` (<https://github.com/ejhigson/texunc>) can be used for automatically printing results tables in LaTeX format.\n",
    "\n",
    "Before running, install `diagnostics` with pip so the utility functions can be accessed, e.g. by running from within the current directory\n",
    "\n",
    "    $ pip install . --user\n",
    "\n",
    "Figure 1 in the paper was produced with `tikz` and is not included. Output plots will be saved to `plots`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up for making plots\n",
    "\n",
    "### Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import nestcheck.plots\n",
    "import nestcheck.diagnostics_tables\n",
    "import nestcheck.estimators as e\n",
    "import diagnostics.results_plots\n",
    "import diagnostics.data_loading\n",
    "import diagnostics.results_utils\n",
    "import diagnostics.settings\n",
    "%matplotlib inline\n",
    "# np.random.seed(0)\n",
    "# pd.set_option('display.width', 200)\n",
    "# matplotlib.rc('text', usetex=True)\n",
    "\n",
    "# Set plot size, font and fontsize to match LaTeX template\n",
    "# --------------------------------------------------------\n",
    "# NB A4 paper is 8.27 \u00d7 11.69 inches (=210 \u00d7 297 mm)\n",
    "# Font: \\T1/ntxtlf/m/n/9\n",
    "# Caption font: \\T1/ntxtlf/m/n/8\n",
    "# Footnote font: \\T1/ntxtlf/m/n/8\n",
    "# Abstract font: \\T1/ntxtlf/m/n/10\n",
    "textwidth = 6.97522 * 0.99  # make 1% smaller to ensure everything fits\n",
    "textheight = 9.43869 * 0.99  # make 1% smaller to ensure everything fits\n",
    "colwidth = 3.32153\n",
    "# Check matplotlib parameters\n",
    "# ---------------------------\n",
    "matplotlib_settings = {'text.usetex': True,\n",
    "                       'font.family': ['serif'],\n",
    "                       'font.serif': ['Times New Roman'],\n",
    "                       'font.size': 8}\n",
    "for key, value in matplotlib_settings.items():\n",
    "    if matplotlib.rcParams.get(key) != value:\n",
    "        print('{}={} - the paper plots use {}'.format(\n",
    "            key, matplotlib.rcParams.get(key), value))\n",
    "        # matplotlib.rcParams[key] = value\n",
    "\n",
    "# Define useful global variables\n",
    "# ------------------------------\n",
    "likelihood_list = ['Gaussian', 'LogGamma mix']  # 'Gaussian shell', 'Rastrigin', 'Rosenbrock']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 2: Triangle Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get runs for plotting\n",
    "# ---------------------\n",
    "# The same runs are used for Figures 2, 3 and 4\n",
    "nrun = 2\n",
    "ndim, nlive, nrepeats = diagnostics.settings.get_default_nd_nl_nr()\n",
    "plot_run_dict = diagnostics.data_loading.get_run_list_dict(\n",
    "    ['LogGamma mix'], nrun, nlive=nlive, nrepeats=nrepeats, ndim=ndim)\n",
    "# Make the plots\n",
    "# --------------\n",
    "for likelihood_name in ['LogGamma mix']:\n",
    "    gplot = diagnostics.results_plots.getdist_plot(\n",
    "        plot_run_dict[likelihood_name], width_inch=colwidth, params=3,\n",
    "        param_limits=diagnostics.settings.get_default_lims(likelihood_name, ndim))\n",
    "    gplot.export('plots/triangle_{}_{}nlive_{}nrepeats.pdf'.format(\n",
    "        likelihood_name.replace(' ', '_'), nlive, nrepeats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 3: Posterior distributions with bootstrap uncertainty estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get runs for plotting\n",
    "# ---------------------\n",
    "# The same runs are used for Figures 2, 3 and 4\n",
    "nrun = 2\n",
    "\n",
    "plot_run_dict = diagnostics.data_loading.get_run_list_dict(\n",
    "    likelihood_list, nrun, nlive=nlive, nrepeats=nrepeats, ndim=ndim)\n",
    "# Settings\n",
    "# --------\n",
    "n_simulate = 50  # 500 for paper\n",
    "npoints = 100  # 200 for paper\n",
    "\n",
    "labels = [diagnostics.results_utils.param_latex_name(i) for i in range(1, 3)]\n",
    "\n",
    "for name in likelihood_list:\n",
    "    lab_list = []\n",
    "    lab_list.append(diagnostics.results_utils.param_latex_name(1))\n",
    "    lab_list.append(diagnostics.results_utils.param_latex_name(2))\n",
    "    if name == 'LogGamma mix':\n",
    "        lab_list.append(diagnostics.results_utils.param_latex_name(3))\n",
    "        lab_list.append(r'$|\\theta|$')\n",
    "    assert len(lab_list) % 2 == 0\n",
    "    for i in range(len(lab_list) // 2):\n",
    "        labels = lab_list[2 * i:2 * (i + 1)]\n",
    "        cache_root = 'bs_param_dists_{}_{}nlive_{}nrepeats_{}sim_{}points_{}'.format(\n",
    "            name.replace(' ', '_'), nlive, nrepeats, n_simulate, npoints, i + 1)\n",
    "        fig = nestcheck.plots.bs_param_dists(\n",
    "            plot_run_dict[name], labels=['${}$'.format(lab) for lab in labels],\n",
    "            fthetas=diagnostics.results_utils.get_ftheta_list(labels),\n",
    "            ftheta_lims=[diagnostics.settings.get_default_lims(name)[lab] for lab in labels],\n",
    "            cache='cache/' + cache_root, figsize=(colwidth, 1),\n",
    "            n_simulate=n_simulate, rasterize_contours=True,\n",
    "            nx=npoints, ny=npoints)\n",
    "        # Ajust figure plot size manually for best use of latex space as\n",
    "        # plt.layout_tight() does not work with the colorbars\n",
    "        fig.subplots_adjust(left=0.05, right=0.93, bottom=0.35, top=0.98)\n",
    "        fig.savefig('plots/' + cache_root + '.pdf', dpi=300)  # only contours are rasterised so dpi does not need to be that high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 4: Parameter logX Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get runs for plotting\n",
    "# ---------------------\n",
    "# The same runs are used for Figures 2, 3 and 4\n",
    "nrun = 2\n",
    "ndim, nlive, nrepeats = diagnostics.settings.get_default_nd_nl_nr()\n",
    "plot_run_dict = diagnostics.data_loading.get_run_list_dict(\n",
    "    likelihood_list, nrun, nlive=nlive, nrepeats=nrepeats, ndim=ndim)\n",
    "\n",
    "# Settings\n",
    "# --------\n",
    "n_simulate = 50  # 500 for paper  \n",
    "npoints = 100  # 100 for paper  \n",
    "\n",
    "\n",
    "for name in likelihood_list:\n",
    "    lab_list = []\n",
    "    lab_list.append(diagnostics.results_utils.param_latex_name(1))\n",
    "    lab_list.append(diagnostics.results_utils.param_latex_name(2))\n",
    "    if name == 'LogGamma mix':\n",
    "        lab_list.append(diagnostics.results_utils.param_latex_name(3))\n",
    "        lab_list.append(r'$|\\theta|$')\n",
    "    labels = lab_list\n",
    "    figsize = (colwidth, 0.4 + 0.8 * len(labels))\n",
    "    bottom_margin = 0.4 / figsize[1]\n",
    "    if name in ['Gaussian', 'Gaussian shell']:\n",
    "        run_list = plot_run_dict[name][:1]\n",
    "    else:\n",
    "        run_list = plot_run_dict[name]\n",
    "    cache_root = 'param_logx_diagram_{}_{}nlive_{}nrepeats_{}sim_{}points'.format(\n",
    "        name.replace(' ', '_'), nlive, nrepeats, n_simulate, npoints)\n",
    "    ftheta_lims = [diagnostics.settings.get_default_lims(name)[lab] for lab in labels]\n",
    "    if name == 'LogGamma mix':\n",
    "        ftheta_lims[0][0] -= 10\n",
    "    fig = nestcheck.plots.param_logx_diagram(\n",
    "        run_list, labels=labels, \n",
    "        fthetas=diagnostics.results_utils.get_ftheta_list(labels),\n",
    "        ftheta_lims=ftheta_lims,\n",
    "        cache='cache/' + cache_root, rasterize_contours=True,\n",
    "        logx_min=diagnostics.settings.default_logx_min(name, ndim),\n",
    "        figsize=figsize, npoints=npoints)\n",
    "    fig.subplots_adjust(left=0.16, right=0.985, bottom=bottom_margin, top=0.995)\n",
    "    fig.savefig('plots/' + cache_root + '.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 5 and Tables: Implementation error bar chart and results tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get error results data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "# --------\n",
    "nrun = 10\n",
    "n_simulate = 100\n",
    "nd_nl_nr_list = [diagnostics.settings.get_default_nd_nl_nr()]\n",
    "\n",
    "# Get data\n",
    "errors_df_in = diagnostics.data_loading.get_results_df(\n",
    "    likelihood_list, nd_nl_nr_list, n_simulate=n_simulate,\n",
    "    nrun=nrun, summary=True, save=True, load=True, thread_pvalue=False,\n",
    "    bs_stat_dist=False, include_rmse=True,\n",
    "    include_true_values=True)\n",
    "\n",
    "# Format_data\n",
    "estimator_names_bar = [e.get_latex_name(est) for est in [e.logz,\n",
    "                                                         e.param_mean,\n",
    "                                                         functools.partial(e.param_mean, param_ind=1),\n",
    "                                                         functools.partial(e.param_mean, param_ind=2)]]\n",
    "                                                         # functools.partial(e.param_mean, param_ind=3)\n",
    "                                                         # e.r_mean,\n",
    "                                                         # e.param_squared_mean]\n",
    "errors_df = errors_df_in.copy()[estimator_names_bar]\n",
    "for i, level in enumerate(['ndim', 'nlive', 'nrepeats']): \n",
    "    errors_df = errors_df.xs(diagnostics.settings.get_default_nd_nl_nr()[i],\n",
    "                             level=level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_df_in # .columns[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot bar chart (Fig 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make bar chart\n",
    "fig = diagnostics.results_plots.ratio_bar_plot(errors_df, figsize=(colwidth, 1.2))\n",
    "savename = 'plots/imp_error_test_{}runs_{}sim_{}nlive_{}nrepeats.pdf'.format(\n",
    "    nrun, n_simulate, nlive, nrepeats)\n",
    "fig.subplots_adjust(left=0.18, right=0.61, bottom=0.2, top=0.96)\n",
    "fig.savefig(savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make results tables\n",
    "str_map = {'true values': 'Correct Result',\n",
    "           'values mean': 'Mean Calculation Result',\n",
    "           'values std': r'Values St.Dev.\\ ',\n",
    "           'values rmse': 'Values RMSE',\n",
    "           'bootstrap std mean': r'Bootstrap St.Dev.\\ ',\n",
    "           'implementation std': r'Implementation St.Dev.\\ ',\n",
    "           'implementation std frac': r'Imp St.Dev. / Val St.Dev.\\ ',\n",
    "           r'Implementation St.Dev.\\  frac': r'Imp St.Dev./Val St.Dev.\\ ',\n",
    "           'mathrm{log}': 'log'}\n",
    "df_dict = {}\n",
    "for likelihood_name in likelihood_list:\n",
    "    df = errors_df.xs(likelihood_name, level='likelihood')\n",
    "    label = 'tab:' + likelihood_name.lower().replace(' ', '_')\n",
    "    caption = ('As in \\Cref{tab:gaussian} but for calculations using the ' + likelihood_name +\n",
    "               r' likelihood~\\eqref{equ:' + likelihood_name.lower().replace(' ', '_') + r'}.')\n",
    "    try:\n",
    "        import texunc\n",
    "        df = texunc.print_latex_df(\n",
    "            df, min_dp=1, min_dp_no_error=4, str_map=str_map, caption=caption,\n",
    "            caption_above=False, label=label, zero_dp_ints=False)\n",
    "        df.index = [str_map[ind] for ind in list(df.index)]\n",
    "    except ImportError:\n",
    "        pass\n",
    "    # Also store the formatted df\n",
    "    df_dict[likelihood_name] = df\n",
    "pd.concat(df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures 7 and 8:  Line plots of errors vs nlive and nrepeats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a data frame of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "# --------\n",
    "nrun_lp = 10\n",
    "n_simulate_lp = 100\n",
    "\n",
    "nd_nl_nr_list = diagnostics.settings.get_nd_nl_nr_list(\n",
    "        nd_list=[2, 4, 10], \n",
    "        nl_list=[10, 20, 50],\n",
    "        nr_list=[1, 2, 5, 10])\n",
    "# Run plots\n",
    "results_df_in = diagnostics.data_loading.get_results_df(\n",
    "    likelihood_list, nd_nl_nr_list, n_simulate=n_simulate_lp,\n",
    "    nrun=nrun_lp, summary=True, save=True, load=True, thread_pvalue=False,\n",
    "    bs_stat_dist=False, include_rmse=True, include_true_values=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make line plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xaxes = ['ndim', 'nlive', 'nrepeats']\n",
    "defaults = diagnostics.settings.get_default_nd_nl_nr()\n",
    "for i, x_to_plot in enumerate(xaxes):\n",
    "    print(x_to_plot)\n",
    "    df_temp = results_df_in\n",
    "    for j, x_to_remove in enumerate(xaxes):\n",
    "        if i != j:\n",
    "            df_temp = df_temp.xs(defaults[j], level=xaxes[j])\n",
    "    for est in [e.logz, e.param_mean]:\n",
    "        estimator_name = e.get_latex_name(est)\n",
    "        print('\\n', estimator_name)\n",
    "        fig = diagnostics.results_plots.get_line_plot(df_temp, estimator_name, figsize=(colwidth, 3))\n",
    "        # Manually adjust saving as described in (https://matplotlib.org/devdocs\n",
    "        # /api/_as_gen/matplotlib.pyplot.subplots_adjust.html)\n",
    "        fig.subplots_adjust(left=0.17, right=0.995, bottom=0.07, top=0.99,\n",
    "                            hspace=0)\n",
    "        savename = 'plots/line_{}_{}runs_{}sim_{}.pdf'.format(\n",
    "            x_to_plot, nrun_lp, n_simulate_lp, est.__name__)\n",
    "        fig.savefig(savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make legend in seperate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(textwidth, 0.3))\n",
    "for i, label in enumerate(['result values', 'mean bootstrap estimate', 'implementation error']):\n",
    "    plt.plot([0,1],[-1,-1], label=label)\n",
    "plt.legend(ncol=3, loc='center')\n",
    "plt.gca().set_ylim(bottom=0)\n",
    "plt.axis('off')\n",
    "fig.savefig('plots/line_plot_legend.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures 9, 11, 12 and 13: Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "# --------\n",
    "# first draft used nrun=500, nlive=1000, nrepeats=5\n",
    "nlive = 200  # 1000 for paper\n",
    "nrepeats = 10\n",
    "nrun = 100  \n",
    "n_simulate = 100  # 100 for paper\n",
    "ndim, nlive, nrepeats = diagnostics.settings.get_default_nd_nl_nr()\n",
    "vals_df_in = diagnostics.data_loading.get_results_df(\n",
    "    likelihood_list, [(ndim, nlive, nrepeats)], n_simulate=n_simulate, nrun=nrun,\n",
    "    summary=False, save=True, load=True, thread_pvalue=True, bs_stat_dist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xlims = {'thread ks pvalue': [0,1],\n",
    "         'thread ks distance': [0,0.3],\n",
    "         'thread earth mover distance': [0, 0.2],\n",
    "         'thread energy distance': [0, 0.4],\n",
    "         'bootstrap ks pvalue': [0,1],\n",
    "         'bootstrap ks distance': [0,1],\n",
    "         'bootstrap earth mover distance': [0, 0.25],\n",
    "         'bootstrap energy distance': [0, 0.8]}\n",
    "\n",
    "for i, est in enumerate([e.param_mean, functools.partial(e.param_mean, param_ind=1)]):\n",
    "    for calc in ['thread ks pvalue', 'bootstrap ks distance', 'bootstrap earth mover distance', 'bootstrap energy distance']:\n",
    "        print(calc)\n",
    "        fig = diagnostics.results_plots.hist_plot(\n",
    "            vals_df_in, calc, e.get_latex_name(est),\n",
    "            likelihood_list=likelihood_list,\n",
    "            xlim=xlims[calc], nbin=50, figsize=(colwidth, 1))\n",
    "        savename = 'plots/hist_{}_theta{}_{}runs_{}sim_{}nlive_{}nrepeats.pdf'.format(\n",
    "            calc.replace(' ', '_'), i + 1, nrun, n_simulate, nlive, nrepeats)\n",
    "        fig.subplots_adjust(left=0.096, right=0.985, bottom=0.29, top=0.98)\n",
    "        fig.savefig(savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 10: 1d KDE distributions of bootstrap sampling error estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "# --------\n",
    "# first draft used nlive=1000, nsimulate=100\n",
    "ndim, nlive, nrepeats = diagnostics.settings.get_default_nd_nl_nr()\n",
    "n_simulate = 100  # paper uses 1000\n",
    "kde_run_dict = diagnostics.data_loading.get_run_list_dict(\n",
    "    likelihood_list, nrun, nlive=nlive, nrepeats=nrepeats, ndim=ndim)\n",
    "\n",
    "estimator_list_1dkde = [e.logz,\n",
    "                        e.param_mean,\n",
    "                        functools.partial(e.param_mean, param_ind=1)]\n",
    "estimator_names_1dkde = [e.get_latex_name(est) for est in estimator_list_1dkde]\n",
    "    \n",
    "bs_dict = {}\n",
    "for likelihood_name in likelihood_list:\n",
    "    bs_dict[likelihood_name] = nestcheck.diagnostics_tables.bs_values_df(\n",
    "        kde_run_dict[likelihood_name], estimator_list_1dkde, estimator_names_1dkde, n_simulate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for likelihood_name in likelihood_list:\n",
    "    print(likelihood_name)\n",
    "    bs_df = bs_dict[likelihood_name].iloc[[2, 3]]\n",
    "    fig = nestcheck.plots.kde_plot_df(\n",
    "        bs_df, figsize=(textwidth * 0.5, 1.2), num_xticks=3)\n",
    "    fig.subplots_adjust(left=0.03, right=0.97, bottom=0.35, top=0.99)\n",
    "    fig.savefig('plots/1dkde_' + likelihood_name.replace(' ', '_') + '_' + str(nlive) + 'nlive_' + str(nrepeats) + 'nrepeats_' + str(n_simulate) + 'sim.pdf')"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {
    "0d5a5c3587954400b5cacf27e95fb2ca": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "15c90a7dbb9c4c408558c34c3aafca6d": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "1b168ce8e2ae456b969317f2be57d9c8": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "1d7d12616d2f4517b341f649848bc226": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "349f2f1e82c24ba2999096e6e64c5d47": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "3e32afd63571447088990de120db071d": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "42e9049bcaee45c7a3842e94e6df35b5": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "4531a2ec0dd24f9b8573b74731f05222": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "4c119b207fa94a3d9b1f3b7f8f4bd457": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "569449d7184241baa585ff7b53f35af9": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "5eb2d8b88e894e18a9ffbe0eed17b998": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "6e53654aa8a544aa9720960498265199": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "77111c0c038b4933bf3891ce79872348": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "798d6f2d36d8463291bc99f88afdb368": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "7e8b20ac815f425a84edf7dee6bdc02a": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "82b2514ce4e642a0b6af927243db004c": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "862f3e22ce9844ed99e3cace0d7f9f2e": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "a0705a7a88ba47ef81840cd51cda1234": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "a64713e83fbf44f29e2c4b7a04d2cac9": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "a66271ed443b4a7f99c0713921a9af3b": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "a9088dff59904535a624e2b38bd997f5": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "a9a6958cd4784384a9f6c23a3dfae616": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "a9acf8f5b15c48e4b61bc57311dea4c9": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "b4fa32a467b84214b0215ff84926b3b0": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "bb8048532f8044559823e6e5bc500d7c": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "c778508297e4446db16de3d7a0d8c054": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "c96cfdf579644f4eaed59373c1e51244": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "d0a735342e7b404f8bb225bb117687bf": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "d732389a92354479bb7f52339b995eab": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "e291e6ffa9a345039fd555e364d5fc44": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "e29a5f0a53fd4a51a94a5ebdc6888f91": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "e69d501ddf764572ace5a3e0116dc306": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "f3331b6766924ad1bd6f63e0990666d5": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}