{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Diagnostics Paper Code\n",
    "\n",
    "Code for making the figures and results tables in \"Diagnostic tests for nested sampling calculations\" ([Higson et al., 2018](https://arxiv.org/abs/1804.06406)). See the paper for a detailed explanation information about the plots and tables produced.\n",
    "\n",
    "Requirements:\n",
    "* Nested sampling runs saved in 'chains' - these can be generated with `generate_data.py`;\n",
    "* `nestcheck`;\n",
    "* `getdist` (<https://github.com/cmbant/getdist>).\n",
    "\n",
    "Optional:\n",
    "* `texunc` (<https://github.com/ejhigson/texunc>) can be used for automatically printing results tables in LaTeX format.\n",
    "\n",
    "Figure 1 in the paper was produced with `tikz` and is not included. Output plots will be saved to `plots`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up for making plots\n",
    "\n",
    "### Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import nestcheck.ns_run_utils\n",
    "import nestcheck.plots\n",
    "import nestcheck.data_processing\n",
    "import nestcheck.diagnostics_tables\n",
    "import nestcheck.estimators as e\n",
    "%matplotlib inline\n",
    "np.random.seed(0)\n",
    "pd.set_option('display.width', 200)\n",
    "\n",
    "# Output settings\n",
    "# ---------------\n",
    "# Set these to match the latex\n",
    "textwidth = 6.39767 * 0.99  # make 1% smaller to ensure everything fits\n",
    "matplotlib.rc('text', usetex=True)\n",
    "matplotlib.rc('font', **{'family': 'serif', 'serif': ['Computer Modern Roman'], 'size': 10})\n",
    "\n",
    "# Define useful global variables\n",
    "# ------------------------------\n",
    "likelihood_list = ['Gaussian', 'Gaussian shell', 'Rastrigin', 'Rosenbrock']\n",
    "estimator_list = [e.logz,\n",
    "                  e.evidence,\n",
    "                  e.param_mean,\n",
    "                  functools.partial(e.param_mean, param_ind=1),\n",
    "                  e.param_squared_mean,\n",
    "                  functools.partial(e.param_cred, probability=0.5),\n",
    "                  functools.partial(e.param_cred, probability=0.84),\n",
    "                  e.r_mean,\n",
    "                  functools.partial(e.r_cred, probability=0.5),\n",
    "                  functools.partial(e.r_cred, probability=0.84)]\n",
    "\n",
    "lims = {'Gaussian':       {r'$\\theta_\\hat{1}$':   [-2, 2],\n",
    "                           r'$\\theta_\\hat{2}$':   [-2, 2],\n",
    "                           r'$\\theta_\\hat{1}^2$': [0, 2.5],\n",
    "                           r'$|\\theta|$':  [0, 2.5]},\n",
    "        'Gaussian shell': {r'$\\theta_\\hat{1}$':   [-4, 4],\n",
    "                           r'$\\theta_\\hat{2}$':   [-4, 4],\n",
    "                           r'$\\theta_\\hat{1}^2$': [0, 8],\n",
    "                           r'$|\\theta|$':  [1, 3]},\n",
    "        'Rosenbrock':     {r'$\\theta_\\hat{1}$':   [-1, 2.5],\n",
    "                           r'$\\theta_\\hat{2}$':   [-1, 5],\n",
    "                           r'$\\theta_\\hat{1}^2$': [0, 4.5],\n",
    "                           r'$|\\theta|$':  [0, 4.5]},\n",
    "        'Rastrigin':     {r'$\\theta_\\hat{1}$':    [-2.5, 2.5],\n",
    "                           r'$\\theta_\\hat{2}$':   [-2.5, 2.5],\n",
    "                           r'$\\theta_\\hat{1}^2$': [0, 5],\n",
    "                           r'$|\\theta|$':  [0, 3]}}\n",
    "fthetas = {r'$\\theta_\\hat{1}$': lambda x: x[:, 0],\n",
    "           r'$\\theta_\\hat{2}$': lambda x: x[:, 1],\n",
    "           r'$\\theta_\\hat{1}^2$': lambda x: x[:, 0] ** 2,\n",
    "           r'$|\\theta|$': lambda x: np.sqrt(np.sum(x ** 2, axis=1))}\n",
    "labels = [r'$\\theta_\\hat{1}$',\n",
    "          r'$\\theta_\\hat{2}$',\n",
    "          r'$\\theta_\\hat{1}^2$',\n",
    "          r'$|\\theta|$']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 2: Triangle Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get runs for plotting\n",
    "# ---------------------\n",
    "# The same runs are used for Figures 2, 3, 4 and 5.\n",
    "nlive = 100\n",
    "nruns = 2\n",
    "nrepeats = 5\n",
    "plot_run_dict = {}\n",
    "for likelihood_name in likelihood_list:\n",
    "    file_root = get_file_root(likelihood_name, nlive, nrepeats)\n",
    "    plot_run_dict[likelihood_name] = nestcheck.data_processing.batch_process_data(\n",
    "        [file_root + '_' + str(i) for i in range(1, nruns + 1)])\n",
    "\n",
    "# Settings\n",
    "# --------\n",
    "\n",
    "getdist_lims = copy.deepcopy(lims)\n",
    "# override some lims\n",
    "getdist_lims['Gaussian'][r'$\\theta_\\hat{1}$'] = [-2.1, 2.1]\n",
    "getdist_lims['Gaussian'][r'$\\theta_\\hat{2}$'] = [-2.1, 2.1]\n",
    "getdist_lims['Rosenbrock'][r'$\\theta_\\hat{1}$'] = [-1.5, 3.5]    \n",
    "\n",
    "# Make the plots\n",
    "# --------------\n",
    "gplot = diagnostics.results_plots.getdist_plot(\n",
    "    plot_run_dict[name], getdist_lims[name], width_inch=0.49 * textwidth)\n",
    "gplot.export('plots/triangle_{}_{}nlive_{}nrepeats.pdf'.format(\n",
    "    name.replace(' ', '_'), nlive, nrepeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 3: Posterior distributions with bootstrap uncertainty estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get runs for plotting\n",
    "# ---------------------\n",
    "# The same runs are used for Figures 2, 3, 4 and 5.\n",
    "nlive = 100\n",
    "nruns = 2\n",
    "nrepeats = 5\n",
    "plot_run_dict = {}\n",
    "for likelihood_name in likelihood_list:\n",
    "    file_root = get_file_root(likelihood_name, nlive, nrepeats)\n",
    "    plot_run_dict[likelihood_name] = nestcheck.data_processing.batch_process_data(\n",
    "        [file_root + '_' + str(i) for i in range(1, nruns + 1)])\n",
    "\n",
    "# Settings\n",
    "# --------\n",
    "n_simulate = 500  # 500 for paper\n",
    "npoints = 200  # 200 for paper\n",
    "\n",
    "labels = [r'$\\theta_\\hat{1}$',\n",
    "          r'$\\theta_\\hat{2}$',\n",
    "          r'$|\\theta|$']\n",
    "\n",
    "\n",
    "for name in likelihood_list:\n",
    "    print(name)\n",
    "    cache_root = 'bs_param_dists_' + name.replace(' ', '_') + '_' + str(nlive) + 'nlive_' + str(nrepeats) + 'nrepeats_' + str(n_simulate) + 'sim_' + str(npoints) + 'points'\n",
    "    fig = nestcheck.plots.bs_param_dists(plot_run_dict[name],\n",
    "                                         labels=labels,\n",
    "                                         fthetas=[fthetas[lab] for lab in labels],\n",
    "                                         ftheta_lims=[lims[name][lab] for lab in labels],\n",
    "                                         cache='cache/' + cache_root,\n",
    "                                         figsize=(textwidth, 1.2),\n",
    "                                         n_simulate=n_simulate,\n",
    "                                         rasterize_contours=True,\n",
    "                                         nx=npoints, ny=npoints)\n",
    "    # Ajust figure plot size manually for best use of latex space as\n",
    "    # plt.layout_tight() does not work with the colorbars\n",
    "    fig.subplots_adjust(left=0.03, right=0.96, bottom=0.34, top=0.98)\n",
    "    fig.savefig('plots/' + cache_root + '.pdf', dpi=300)  # only contours are rasterised so dpi does not need to be that high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 4 and Fig 5: Parameter logX Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get runs for plotting\n",
    "# ---------------------\n",
    "# The same runs are used for Figures 2, 3, 4 and 5.\n",
    "nlive = 100\n",
    "nruns = 2\n",
    "nrepeats = 5\n",
    "plot_run_dict = {}\n",
    "for likelihood_name in likelihood_list:\n",
    "    file_root = get_file_root(likelihood_name, nlive, nrepeats)\n",
    "    plot_run_dict[likelihood_name] = nestcheck.data_processing.batch_process_data(\n",
    "        [file_root + '_' + str(i) for i in range(1, nruns + 1)])\n",
    "\n",
    "# Settings\n",
    "# --------\n",
    "n_simulate = 500  # 500 for paper  \n",
    "npoints = 100  # 100 for paper  \n",
    "\n",
    "\n",
    "logx_min = {'Gaussian': -10,\n",
    "            'Gaussian shell': -8,\n",
    "            'Rosenbrock': -12,\n",
    "            'Rastrigin': -15}\n",
    "labels = [r'$\\theta_\\hat{1}$',\n",
    "          r'$\\theta_\\hat{2}$',\n",
    "          r'$|\\theta|$']\n",
    "\n",
    "\n",
    "for name in likelihood_list:\n",
    "    if name in ['Gaussian', 'Gaussian shell']:\n",
    "        run_list = plot_run_dict[name][:1]\n",
    "    else:\n",
    "        run_list = plot_run_dict[name]\n",
    "    cache_root = 'param_logx_diagram_' + name.replace(' ', '_') + '_' + str(nlive) + 'nlive_' + str(nrepeats) + 'nrepeats_' + str(n_simulate) + 'sim'\n",
    "    cache_root += '_' + str(npoints) + 'points'\n",
    "    if len(run_list) != 1:\n",
    "        cache_root += '_' + str(len(run_list)) + 'runs'\n",
    "    fig = nestcheck.plots.param_logx_diagram(run_list,\n",
    "                                             labels=labels,\n",
    "                                             fthetas=[fthetas[lab] for lab in labels],\n",
    "                                             ftheta_lims=[lims[name][lab] for lab in labels],\n",
    "                                             cache='cache/' + cache_root,\n",
    "                                             logx_min=logx_min[name],\n",
    "                                             npoints=npoints,\n",
    "                                             rasterize_contours=True,\n",
    "                                             figsize=(textwidth * 0.49, 5))\n",
    "    fig.subplots_adjust(left=0.19, right=0.97, bottom=0.08, top=0.995)\n",
    "    fig.savefig('plots/' + cache_root + '.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 6 and Tables 1-4: Implementation error bar chart and results tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the true values of the estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dyPolyChord.likelihoods as likelihoods\n",
    "import scipy.integrate\n",
    "\n",
    "prior_scale = 10.\n",
    "\n",
    "def integrand_z(x2, x1, pc_like):\n",
    "    return np.exp(pc_like([x1, x2])[0]) / ((2 * prior_scale) ** 2)\n",
    "\n",
    "def integrand_func_not_normed(x2, x1, pc_like, ftheta):\n",
    "    return ftheta((x1, x2)) * np.exp(pc_like([x1, x2])[0]) / ((2 * prior_scale) ** 2)\n",
    "\n",
    "\n",
    "tv_fthetas = {}\n",
    "tv_fthetas[e.get_latex_name(e.param_mean)] = lambda x: x[0]\n",
    "tv_fthetas[e.get_latex_name(functools.partial(e.param_mean, param_ind=1))] = lambda x: x[1]\n",
    "tv_fthetas[e.get_latex_name(e.param_squared_mean)] = lambda x: x[0] ** 2\n",
    "tv_fthetas[e.get_latex_name(functools.partial(e.param_squared_mean, param_ind=1))] = lambda x: x[1] ** 2\n",
    "tv_fthetas[e.get_latex_name(e.r_mean)] = lambda x: np.sqrt(x[0] ** 2 + x[1] ** 2)\n",
    "\n",
    "true_values_dict = {}\n",
    "options = {\"epsabs\": 1.49e-11, \"epsrel\": 1.49e-11, 'limit': 5000}\n",
    "for like in [likelihoods.gaussian, likelihoods.gaussian_shell, likelihoods.rastrigin, likelihoods.rosenbrock]:\n",
    "    name = like.__name__.replace('_', ' ').title().replace('Shell', 'shell')\n",
    "    print(name)\n",
    "    z = scipy.integrate.nquad(integrand_z, ranges=[(-prior_scale, prior_scale), (-prior_scale, prior_scale)],\n",
    "                              args=(like,), opts=options)\n",
    "    true_values_dict[name] = {}\n",
    "    true_values_dict[name][e.get_latex_name(e.logz)] = np.log(z[0])\n",
    "\n",
    "    for ftheta_name, ftheta in tv_fthetas.items():\n",
    "        val = scipy.integrate.nquad(integrand_func_not_normed, ranges=[(-prior_scale, prior_scale), (-prior_scale, prior_scale)],\n",
    "                                    args=(like, ftheta), opts=options)\n",
    "        true_values_dict[name][ftheta_name] = val[0] / z[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get error results data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "# --------\n",
    "nlive = 100\n",
    "nrepeats = 5\n",
    "n_runs = 500\n",
    "n_simulate = 100\n",
    "\n",
    "\n",
    "# Get data\n",
    "errors_df = diagnostics.results_utils.get_results_df(\n",
    "    likelihood_list, [(nlive, nrepeats)], estimator_list, n_simulate=n_simulate,\n",
    "    n_runs=n_runs, summary=True, save=True, load=True, thread_pvalue=False,\n",
    "    bs_stat_dist=False, true_values_dict=true_values_dict, include_rmse=True,\n",
    "    include_true_values=True)\n",
    "\n",
    "# Format_data\n",
    "estimator_names_bar = [e.get_latex_name(est) for est in [e.logz,\n",
    "                                                         e.param_mean,\n",
    "                                                         functools.partial(e.param_mean, param_ind=1),\n",
    "                                                         e.r_mean,\n",
    "                                                         e.param_squared_mean]]\n",
    "errors_df = errors_df.xs(nrepeats, level='nrepeats').xs(nlive, level='nlive')[estimator_names_bar]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot bar chart (Fig 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make bar chart\n",
    "ratio_plot = errors_df.xs('implementation std frac', level='calculation type')\n",
    "ratio_plot = ratio_plot.reorder_levels([1, 0]).T\n",
    "fig = plt.figure(figsize=(textwidth * 0.8, 2))\n",
    "ax = fig.add_subplot(111)\n",
    "ratio_plot['value'].plot.bar(yerr=ratio_plot['uncertainty'], ax=ax)\n",
    "# Add line showing 1/sqrt(2)\n",
    "ax.axhline(2 ** (-0.5), color='black',\n",
    "           linestyle='dashed', linewidth=1)\n",
    "# ax = plt.gca()\n",
    "ax.set_ylim([0, 1])\n",
    "ax.set_ylabel('Imp St.Dev. / Values St.Dev.', labelpad=10)\n",
    "ax.legend(bbox_to_anchor=(1.02, 1), title='Likelihood')\n",
    "plt.xticks(rotation=0)\n",
    "savename = ('plots/imp_error_test_' + str(n_runs) + 'runs_' + str(n_simulate) + 'sim_' + str(nlive) + 'nlive_'+\n",
    "            str(nrepeats) + 'nrepeats.pdf')\n",
    "fig.subplots_adjust(left=0.11, right=0.7, bottom=0.14, top=0.97)\n",
    "fig.savefig(savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make results tables\n",
    "str_map = {'true values': 'Correct Result',\n",
    "           'values mean': 'Mean Calculation Result',\n",
    "           'values std': r'Values St.Dev.\\ ',\n",
    "           'values rmse': 'Values RMSE',\n",
    "           'bootstrap std mean': r'Bootstrap St.Dev.\\ ',\n",
    "           'implementation std': r'Implementation St.Dev.\\ ',\n",
    "           'implementation std frac': r'Imp St.Dev. / Val St.Dev.\\ ',\n",
    "           r'Implementation St.Dev.\\  frac': r'Imp St.Dev./Val St.Dev.\\ ',\n",
    "           'mathrm{log}': 'log'}\n",
    "df_dict = {}\n",
    "for likelihood_name in likelihood_list:\n",
    "    df = errors_df.xs(likelihood_name, level='likelihood')\n",
    "    label = 'tab:' + likelihood_name.lower().replace(' ', '_')\n",
    "    caption = ('As in \\Cref{tab:gaussian} but for calculations using the ' + likelihood_name +\n",
    "               r' likelihood~\\eqref{equ:' + likelihood_name.lower().replace(' ', '_') + r'}.')\n",
    "    try:\n",
    "        import texunc\n",
    "        df = texunc.print_latex_df(\n",
    "            df, min_dp=1, min_dp_no_error=4, str_map=str_map, caption=caption,\n",
    "            caption_above=False, label=label, zero_dp_ints=False)\n",
    "    except ImportError:\n",
    "        pass\n",
    "    # Also store the formatted df\n",
    "    df.index = [str_map[ind] for ind in list(df.index)]\n",
    "    df_dict[likelihood_name] = df\n",
    "pd.concat(df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures 7 and 8:  Line plots of errors vs nlive and nrepeats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a data frame of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "# --------\n",
    "n_runs_lp = 500\n",
    "n_simulate_lp = 10\n",
    "nlive_nrepeats_list = [(nl, 5) for nl in [10, 20, 50, 100, 200, 500, 1000]]\n",
    "nlive_nrepeats_list += [(100, nr) for nr in [1, 2, 10, 20, 50, 100, 200, 500, 1000]]\n",
    "# Run plots\n",
    "results_df_in = diagnostics.results_utils.get_results_df(\n",
    "    likelihood_list, nlive_nrepeats_list, estimator_list, n_simulate=n_simulate_lp,\n",
    "    n_runs=n_runs_lp, summary=True, save=True, load=True, thread_pvalue=False,\n",
    "    bs_stat_dist=False, true_values_dict=true_values_dict, include_rmse=True,\n",
    "    include_true_values=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make line plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "linestyles = ['-', '--', ':', '-.']\n",
    "x_label_map = {'nlive': '{\\sc PolyChord} number of live points', 'nrepeats': '{\\sc PolyChord} \\\\texttt{num\\_repeats}'}\n",
    "ests_for_line_plot = [e.logz, e.param_mean]\n",
    "est_savename_map = {}\n",
    "for est in ests_for_line_plot:\n",
    "    est_savename_map[e.get_latex_name(est)] = est.__name__\n",
    "for df_temp in [results_df_in.xs(5, level='nrepeats'), results_df_in.xs(100, level='nlive')]:\n",
    "    for estimator_name in [e.get_latex_name(est) for est in ests_for_line_plot]:\n",
    "        print(estimator_name)\n",
    "        fig, axes = plt.subplots(nrows=len(likelihood_list), ncols=1, sharex=True, figsize=(textwidth / 2, 6))\n",
    "        fig.subplots_adjust(hspace=0)\n",
    "        for nlike, likelihood_name in enumerate(likelihood_list):\n",
    "            ax = axes[nlike]\n",
    "            for nc, calc in enumerate(['values std', 'bootstrap std mean', 'implementation std']):\n",
    "                ser = df_temp.xs(likelihood_name, level='likelihood').xs(calc, level='calculation type')[estimator_name]\n",
    "                ser = ser.sort_index()\n",
    "                ser.xs('value', level='result type').plot.line(\n",
    "                        yerr=ser.xs('uncertainty', level='result type'),\n",
    "                        ax=ax, label=calc, linestyle=linestyles[nc])\n",
    "            ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "            if 'nlive' in df_temp.index.names and likelihood_name == 'Gaussian' and estimator_name == e.get_latex_name(e.param_mean):\n",
    "                ax.set_yticks([0, 0.05, 0.1])\n",
    "            ax.set_xscale('log')\n",
    "            ax.set_ylabel('St.Dev.')\n",
    "            title = likelihood_name.title().replace('_', ' ').replace('Shell', 'shell') + ' ' + estimator_name\n",
    "            ax.set_title(title, y=0.72)\n",
    "            # make sure the labels of plots above and below each other don't clash\n",
    "            ax.set_ylim([0, ax.get_yticks()[-1]])\n",
    "            ax.tick_params(top=True, direction='inout')\n",
    "            if nlike != 0:\n",
    "                labels = ax.get_yticks().tolist()\n",
    "                ax.set_yticks(labels[:-1])\n",
    "            if nlike == len(likelihood_list) - 1:\n",
    "                ax.set_xlabel(x_label_map[ax.get_xlabel()])\n",
    "        savename = 'plots/line'\n",
    "        if 'nlive' in df_temp.index.names:\n",
    "            savename += '_nlive'\n",
    "        elif 'nrepeats' in df_temp.index.names:\n",
    "            savename += '_nrepeats'\n",
    "        savename += '_' + str(n_runs_lp) + 'runs_' + str(n_simulate_lp) + 'sim_' + est_savename_map[estimator_name] + '.pdf'\n",
    "        # Manually adjust saving as described in https://matplotlib.org/devdocs/api/_as_gen/matplotlib.pyplot.subplots_adjust.html\n",
    "        fig.subplots_adjust(hspace=0, left=0.17, right=0.995, bottom=0.07, top=0.99)\n",
    "        fig.savefig(savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make legend in seperate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(textwidth, 0.3))\n",
    "for i, label in enumerate(['result values', 'mean bootstrap estimate', 'implementation error']):\n",
    "    plt.plot([0,1],[-1,-1], label=label)\n",
    "plt.legend(ncol=3, loc='center')\n",
    "plt.gca().set_ylim(bottom=0)\n",
    "plt.axis('off')\n",
    "fig.savefig('plots/line_plot_legend.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures 9, 11, 12 and 13: Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "# --------\n",
    "nlive = 1000\n",
    "nrepeats = 5\n",
    "n_runs = 500\n",
    "n_simulate = 1000\n",
    "vals_df_in = diagnostics.results_utils.get_results_df(\n",
    "    likelihood_list, [(nlive, nrepeats)], estimator_list, n_simulate=nsimulate, n_runs=n_runs,\n",
    "    summary=False, save=True, load=True, thread_pvalue=True, bs_stat_dist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_df_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xlims = {'thread ks pvalue': [0,1],\n",
    "         'thread ks distance': [0,0.3],\n",
    "         'thread earth mover distance': [0, 0.2],\n",
    "         'thread energy distance': [0, 0.4],\n",
    "         'bootstrap ks pvalue': [0,1],\n",
    "         'bootstrap ks distance': [0,1],\n",
    "         'bootstrap earth mover distance': [0, 0.25],\n",
    "         'bootstrap energy distance': [0, 0.8]}\n",
    "\n",
    "for i, est in enumerate([e.param_mean, functools.partial(e.param_mean, param_ind=1)]):\n",
    "    for calc in ['thread ks pvalue', 'bootstrap ks distance', 'bootstrap earth mover distance', 'bootstrap energy distance']:\n",
    "        print(calc)\n",
    "        fig = diagnostics.results_plots.hist_plot(vals_df_in, calc, e.get_latex_name(est), xlims[calc], nbin=50, figsize=(textwidth, 1.4))\n",
    "        savename = 'plots/hist_' + calc.replace(' ', '_') + '_theta' + str(i + 1) + '_' + str(n_runs) + 'runs_' + str(n_simulate) + 'sim_' + str(nlive) + 'nlive_'+ str(nrepeats) + 'nrepeats'\n",
    "        savename = savename.replace('.', '_') + '.pdf'\n",
    "        fig.subplots_adjust(left=0.096, right=0.985, bottom=0.29, top=0.98)\n",
    "        fig.savefig(savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 10: 1d KDE distributions of bootstrap sampling error estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "# --------\n",
    "nlive = 1000\n",
    "nruns = 5\n",
    "nrepeats = 5\n",
    "n_simulate = 1000\n",
    "\n",
    "# Get runs\n",
    "kde_run_dict = {}\n",
    "for likelihood_name in likelihood_list:\n",
    "    file_root = get_file_root(likelihood_name, nlive, nrepeats)\n",
    "    kde_run_dict[likelihood_name] = nestcheck.data_processing.batch_process_data(\n",
    "        [file_root + '_' + str(i) for i in range(1, nruns + 1)])\n",
    "\n",
    "estimator_list_1dkde = [e.logz,\n",
    "                        e.param_mean,\n",
    "                        functools.partial(e.param_mean, param_ind=1)]\n",
    "estimator_names_1dkde = [e.get_latex_name(est) for est in estimator_list_1dkde]\n",
    "    \n",
    "bs_dict = {}\n",
    "for likelihood_name in likelihood_list:\n",
    "    bs_dict[likelihood_name] = nestcheck.diagnostics_tables.bs_values_df(\n",
    "        kde_run_dict[likelihood_name], estimator_list_1dkde, estimator_names_1dkde, n_simulate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for likelihood_name in likelihood_list:\n",
    "    print(likelihood_name)\n",
    "    bs_df = bs_dict[likelihood_name].iloc[[2, 3]]\n",
    "    fig = nestcheck.plots.kde_plot_df(\n",
    "        bs_df, figsize=(textwidth * 0.5, 1.2), num_xticks=2)\n",
    "    fig.subplots_adjust(left=0.03, right=0.97, bottom=0.35, top=0.99)\n",
    "    fig.savefig('plots/1dkde_' + likelihood_name.replace(' ', '_') + '_' + str(nlive) + 'nlive_' + str(nrepeats) + 'nrepeats_' + str(n_simulate) + 'sim.pdf')"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {
    "0d5a5c3587954400b5cacf27e95fb2ca": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "15c90a7dbb9c4c408558c34c3aafca6d": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "1b168ce8e2ae456b969317f2be57d9c8": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "1d7d12616d2f4517b341f649848bc226": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "349f2f1e82c24ba2999096e6e64c5d47": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "3e32afd63571447088990de120db071d": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "42e9049bcaee45c7a3842e94e6df35b5": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "4531a2ec0dd24f9b8573b74731f05222": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "4c119b207fa94a3d9b1f3b7f8f4bd457": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "569449d7184241baa585ff7b53f35af9": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "5eb2d8b88e894e18a9ffbe0eed17b998": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "6e53654aa8a544aa9720960498265199": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "77111c0c038b4933bf3891ce79872348": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "798d6f2d36d8463291bc99f88afdb368": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "7e8b20ac815f425a84edf7dee6bdc02a": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "82b2514ce4e642a0b6af927243db004c": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "862f3e22ce9844ed99e3cace0d7f9f2e": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "a0705a7a88ba47ef81840cd51cda1234": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "a64713e83fbf44f29e2c4b7a04d2cac9": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "a66271ed443b4a7f99c0713921a9af3b": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "a9088dff59904535a624e2b38bd997f5": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "a9a6958cd4784384a9f6c23a3dfae616": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "a9acf8f5b15c48e4b61bc57311dea4c9": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "b4fa32a467b84214b0215ff84926b3b0": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "bb8048532f8044559823e6e5bc500d7c": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "c778508297e4446db16de3d7a0d8c054": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "c96cfdf579644f4eaed59373c1e51244": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "d0a735342e7b404f8bb225bb117687bf": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "d732389a92354479bb7f52339b995eab": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "e291e6ffa9a345039fd555e364d5fc44": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "e29a5f0a53fd4a51a94a5ebdc6888f91": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "e69d501ddf764572ace5a3e0116dc306": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "f3331b6766924ad1bd6f63e0990666d5": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}